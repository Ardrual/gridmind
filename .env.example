
# Google AI Studio / Gemini API
# Obtain an API key from: https://aistudio.google.com/u/0/app/apikey
# If both GOOGLE_API_KEY and GEMINI_API_KEY are set, GOOGLE_API_KEY is used.
GOOGLE_API_KEY=

# Alternative env name supported by the SDK (either this or GOOGLE_API_KEY)
GEMINI_API_KEY=

# Optional: override the embedding model used during ingest.
# If left empty or unset, defaults to: gemini-embedding-001
GEMINI_EMBEDDING_MODEL=
# Example alternative model:
# GEMINI_EMBEDDING_MODEL=text-embedding-004

# Optional: if you configured a custom output dimensionality during ingest,
# specify it here so query-time embeddings match the same dimensionality.
# e.g., 768, 1536, 3072
GEMINI_EMBEDDING_DIM=

# LLM (generator) model used at query-time. Does not affect embeddings.
# Defaults to a fast model; you can override to a larger model if desired.
GEMINI_LLM_MODEL=gemini-1.5-flash

# Chroma vector store location and collection name for retrieval
CHROMA_DB_DIR=data/chroma
CHROMA_COLLECTION=docs

# Vector store backend selection: chroma (default) or pgvector
VECTOR_BACKEND=chroma

# Postgres/pgvector configuration (used when VECTOR_BACKEND=pgvector)
# Preferred URI format for langchain-postgres is SQLAlchemy-style with psycopg v3
# e.g., postgresql+psycopg://user:pass@host:5432/dbname
PGVECTOR_URL=
# Optional: collection/namespace name in pgvector
PGVECTOR_COLLECTION=docs
